{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Monzo User Sentiment & Feature Insights Dashboard",
   "id": "37c8d0d0e1301107"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\"\"\"\n",
    "============================================================\n",
    "Notebook: 01_data_exploration.ipynb\n",
    "Author: James O. Adeshina\n",
    "Version: 1.0  |  October 2025\n",
    "============================================================\n",
    "\n",
    "Purpose:\n",
    "--------\n",
    "This notebook performs the initial data ingestion and exploratory\n",
    "data analysis (EDA) for Monzo app reviews exported from AppFollow.\n",
    "\n",
    "It aims to:\n",
    "    â€¢ Validate the structure and quality of the raw review datasets\n",
    "    â€¢ Unify Apple App Store and Google Play Store schemas\n",
    "    â€¢ Identify cleaning requirements (duplicates, nulls, non-English)\n",
    "    â€¢ Explore rating and review distributions\n",
    "    â€¢ Provide summary insights to guide the next stages:\n",
    "        - Data cleaning & normalization\n",
    "        - Thematic tagging\n",
    "        - Sentiment analysis\n",
    "============================================================\n",
    "\"\"\""
   ],
   "id": "d9c545f9baf22a8a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ------------------------------------------------------------\n",
    "# 1. Import Libraries\n",
    "# ------------------------------------------------------------\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from langdetect import detect, DetectorFactory\n",
    "from wordcloud import WordCloud"
   ],
   "id": "6d1d34b95d904e3a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Reproducibility for language detection\n",
    "DetectorFactory.seed = 42\n",
    "\n",
    "# Display settings\n",
    "pd.set_option(\"display.max_columns\", 50)\n",
    "sns.set(style=\"whitegrid\", palette=\"muted\", font_scale=1.1)\n"
   ],
   "id": "fb175f3269469c9a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ------------------------------------------------------------\n",
    "# 2. Define File Paths\n",
    "# ------------------------------------------------------------\n",
    "APPSTORE_PATH = \"../data/raw/appstore/monzo_appstore_2015_2025.csv\"\n",
    "GOOGLEPLAY_PATHS = [\n",
    "    \"../data/raw/googleplay/monzo_googleplay_2015_2019.csv\",\n",
    "    \"../data/raw/googleplay/monzo_googleplay_2019_2021.csv\",\n",
    "    \"../data/raw/googleplay/monzo_googleplay_2022_2025.csv\"\n",
    "]"
   ],
   "id": "410dc0218bf8fdfc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def read_appfollow_csv(path):\n",
    "    \"\"\"\n",
    "    Read AppFollow export:\n",
    "    - skip 'sep=' and 'From:' lines\n",
    "    - use line 3 as header\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(\n",
    "        path,\n",
    "        sep=\",\",\n",
    "        skiprows=2,\n",
    "        engine=\"python\",\n",
    "        encoding=\"utf-8\",\n",
    "        on_bad_lines=\"skip\"\n",
    "    )\n",
    "    print(f\"{os.path.basename(path)} â†’ {df.shape[0]} rows Ã— {df.shape[1]} cols\")\n",
    "    return df"
   ],
   "id": "69b90e9f1d3502f9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "appstore_df  = read_appfollow_csv(\"../data/raw/appstore/monzo_appstore_2015_2025.csv\")\n",
    "gplay_15_19  = read_appfollow_csv(\"../data/raw/googleplay/monzo_googleplay_2015_2019.csv\")\n",
    "gplay_19_21  = read_appfollow_csv(\"../data/raw/googleplay/monzo_googleplay_2019_2021.csv\")\n",
    "gplay_22_25  = read_appfollow_csv(\"../data/raw/googleplay/monzo_googleplay_2022_2025.csv\")\n"
   ],
   "id": "b54ede8e2db7ae74"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ------------------------------------------------------------\n",
    "# 3. Data Ingestion (Staged â€” Inspect Before Merge)\n",
    "# ------------------------------------------------------------\n",
    "\"\"\"\n",
    "Purpose:\n",
    "---------\n",
    "This stage loads the raw Monzo App Store and Google Play Store\n",
    "review datasets individually for inspection, without merging them yet.\n",
    "\n",
    "Key Features:\n",
    "-------------\n",
    "- Skips the first two metadata lines in AppFollow exports ('sep=' and 'From:').\n",
    "- Ensures UTF-8 encoding to preserve emojis and multilingual text.\n",
    "- Prints shape, column names, and sample rows for validation.\n",
    "- Returns a dictionary of DataFrames keyed by dataset name.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def read_appfollow_csv(path):\n",
    "    \"\"\"\n",
    "    Read AppFollow export:\n",
    "    - Skip 'sep=' and 'From:' lines (first two)\n",
    "    - Use line 3 as the header\n",
    "    - Preserve emojis and multilingual characters\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(\n",
    "            path,\n",
    "            sep=\",\",                # AppFollow exports use commas\n",
    "            skiprows=2,             # skip metadata lines\n",
    "            engine=\"python\",\n",
    "            encoding=\"utf-8\",\n",
    "            on_bad_lines=\"skip\"     # skip problematic lines without stopping\n",
    "        )\n",
    "        print(f\"âœ… {os.path.basename(path)} â†’ {df.shape[0]:,} rows Ã— {df.shape[1]} cols\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error reading {os.path.basename(path)}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def load_individual_datasets(appstore_path, google_paths):\n",
    "    \"\"\"\n",
    "    Load App Store and Google Play review datasets individually for inspection.\n",
    "    Returns a dictionary of DataFrames for each dataset.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    appstore_path : str\n",
    "        Path to the App Store CSV export.\n",
    "    google_paths : list\n",
    "        List of paths to the Google Play CSV exports.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Dictionary of DataFrames with dataset names as keys.\n",
    "    \"\"\"\n",
    "    datasets = {}\n",
    "\n",
    "    # --- Load App Store ---\n",
    "    print(\"\\nðŸ“‚ Loading App Store dataset...\")\n",
    "    appstore_df = read_appfollow_csv(APPSTORE_PATH)\n",
    "    datasets[\"appstore\"] = appstore_df\n",
    "    print(f\"   â†’ Columns: {list(appstore_df.columns)}\\n\")\n",
    "\n",
    "    # --- Load Google Play datasets ---\n",
    "    print(\"ðŸ“‚ Loading Google Play datasets...\")\n",
    "    for path in GOOGLEPLAY_PATHS:\n",
    "        name = os.path.basename(path).replace(\".csv\", \"\")\n",
    "        df_part = read_appfollow_csv(path)\n",
    "        datasets[name] = df_part\n",
    "        print(f\"   â†’ {name} Columns: {list(df_part.columns)}\\n\")\n",
    "\n",
    "    print(\"\\nâœ… All datasets successfully loaded and ready for schema review.\\n\")\n",
    "    return datasets\n",
    "\n",
    "\n"
   ],
   "id": "323f33f62e6947e0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ------------------------------------------------------------\n",
    "# Execute Data Loading\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "datasets = load_individual_datasets(APPSTORE_PATH, GOOGLEPLAY_PATHS)\n"
   ],
   "id": "6971173413bbda8b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ------------------------------------------------------------\n",
    "# 4. Schema & Structural Review\n",
    "# ------------------------------------------------------------\n",
    "\"\"\"\n",
    "Purpose:\n",
    "---------\n",
    "Before merging the datasets, this stage performs a detailed structural\n",
    "audit of the individual App Store and Google Play Store review datasets.\n",
    "\n",
    "Objectives:\n",
    "------------\n",
    "1. Compare and validate column schemas across all datasets.\n",
    "2. Inspect column data types and ensure consistency for merging.\n",
    "3. Identify missing values and structural anomalies.\n",
    "4. Display representative samples to confirm review text quality.\n",
    "\n",
    "Outcome:\n",
    "---------\n",
    "This ensures all datasets are harmonised, complete, and merge-ready.\n",
    "\"\"\"\n"
   ],
   "id": "f216b29784b32d65"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ------------------------------------------------------------\n",
    "# 4.1 Column Comparison Across Datasets\n",
    "# ------------------------------------------------------------\n",
    "print(\"ðŸ§¾ Comparing column structures across datasets...\\n\")\n",
    "\n",
    "# Extract and sort columns per dataset\n",
    "schema_dict = {name: sorted(df.columns.tolist()) for name, df in datasets.items()}\n",
    "\n",
    "# Find the maximum number of columns among all datasets\n",
    "max_len = max(len(cols) for cols in schema_dict.values())\n",
    "\n",
    "# Pad shorter lists with empty strings to equalize length\n",
    "for name in schema_dict:\n",
    "    schema_dict[name] += [\"\"] * (max_len - len(schema_dict[name]))\n",
    "\n",
    "# Build schema comparison DataFrame safely\n",
    "schema_comparison = pd.DataFrame(schema_dict).T\n",
    "schema_comparison.columns = [f\"Col_{i+1}\" for i in range(max_len)]\n",
    "\n",
    "display(schema_comparison.head(10))\n",
    "\n"
   ],
   "id": "5da2321536180467"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "# Identify common and unique columns\n",
    "all_columns = set().union(*[df.columns for df in datasets.values()])\n",
    "common_columns = set.intersection(*[set(df.columns) for df in datasets.values()])\n",
    "unique_columns = {name: list(set(df.columns) - common_columns) for name, df in datasets.items()}\n",
    "\n",
    "print(f\"\\nâœ… Total unique columns across all datasets: {len(all_columns)}\")\n",
    "print(f\"âœ… Columns common to all datasets ({len(common_columns)}):\")\n",
    "print(sorted(common_columns))\n",
    "\n",
    "print(f\"\\nâš™ï¸ Platform-specific (unique) columns:\")\n",
    "for name, cols in unique_columns.items():\n",
    "    if cols:\n",
    "        print(f\"   - {name}: {cols}\")"
   ],
   "id": "d64805115be3b4f2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4.2 Data Type Inspection\n",
    "# ------------------------------------------------------------\n",
    "print(\"\\nðŸ“Š Data Type Summary:\\n\")\n",
    "for name, df in datasets.items():\n",
    "    print(f\"ðŸ§© {name.upper()} ({df.shape[0]:,} rows Ã— {df.shape[1]} cols)\")\n",
    "    print(df.dtypes.value_counts())\n",
    "    print(\"-\" * 60)\n"
   ],
   "id": "3a045dd10ad958f3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4.3 Missing Value Overview\n",
    "# ------------------------------------------------------------\n",
    "print(\"\\nðŸ” Missing Value Overview (Top 10 columns with missing counts per dataset):\\n\")\n",
    "for name, df in datasets.items():\n",
    "    missing_summary = (\n",
    "        df.isna().sum()\n",
    "        .sort_values(ascending=False)\n",
    "        .head(10)\n",
    "        .reset_index()\n",
    "        .rename(columns={'index': 'Column', 0: 'Missing Count'})\n",
    "    )\n",
    "    print(f\"\\nðŸ“‚ {name.upper()} Dataset Missing Values:\")\n",
    "    display(missing_summary)\n",
    "    print(\"-\" * 60)\n"
   ],
   "id": "e03809fd87bdceba"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4.4 Sample Review Inspection\n",
    "# ------------------------------------------------------------\n",
    "print(\"\\nðŸ’¬ Sampling reviews for content validation...\\n\")\n",
    "for name, df in datasets.items():\n",
    "    print(f\"ðŸ—‚ï¸ {name.upper()} â€” Sample Reviews\")\n",
    "    display(df[['Submission date', 'Rating', 'Review']].sample(3, random_state=42))\n",
    "    print(\"-\" * 60)\n"
   ],
   "id": "d11db41ac8ca84be"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ------------------------------------------------------------\n",
    "# 4.5 Summary Notes\n",
    "# ------------------------------------------------------------\n",
    "\"\"\"\n",
    "Summary:\n",
    "---------\n",
    "- Confirmed which columns are shared across all datasets.\n",
    "- Identified platform-specific fields to be harmonised or dropped.\n",
    "- Inspected data types to ensure compatibility for merging.\n",
    "- Validated data quality and presence of meaningful user reviews.\n",
    "\n",
    "Next Step:\n",
    "-----------\n",
    "Proceed to Section 5 â€” Schema Harmonisation & Merging,\n",
    "where columns will be standardised and all reviews unified into\n",
    "a single master dataset: 'Monzo_Reviews_Master.csv'.\n",
    "\"\"\"\n"
   ],
   "id": "36ab4424819fe654"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ------------------------------------------------------------\n",
    "# 5. Schema Harmonisation & Merge Pipeline\n",
    "# ------------------------------------------------------------\n",
    "\"\"\"\n",
    "Purpose:\n",
    "---------\n",
    "To harmonise column names, ensure consistent structure across all\n",
    "review datasets, add platform identifiers, and merge them into one\n",
    "master dataset for downstream analysis (sentiment, themes, Power BI).\n",
    "\n",
    "Key Features:\n",
    "--------------\n",
    "- Aligns App Store and Google Play columns via a mapping dictionary.\n",
    "- Drops redundant or empty columns (e.g., Notes, Tags, Semantic fields).\n",
    "- Adds a 'platform' column for source tracking (iOS / Android).\n",
    "- Converts key columns to proper datatypes (date, numeric).\n",
    "- Exports the unified dataset as 'Monzo_Reviews_Master.csv'.\n",
    "\"\"\""
   ],
   "id": "72c6646ce5bee57b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5.1 Column Mapping (Standardisation Dictionary)\n",
    "# ------------------------------------------------------------\n",
    "column_mapping = {\n",
    "    \"Submission date\": \"review_date\",\n",
    "    \"AppID\": \"app_id\",\n",
    "    \"AppName\": \"app_name\",\n",
    "    \"Country\": \"country\",\n",
    "    \"Review Language\": \"review_language\",\n",
    "    \"Version\": \"app_version\",\n",
    "    \"Author\": \"author_name\",\n",
    "    \"Rating\": \"rating\",\n",
    "    \"Title\": \"review_title\",\n",
    "    \"Review\": \"review_text\",\n",
    "    \"Reply Date\": \"developer_reply_date\",\n",
    "    \"Reply Delta\": \"developer_reply_delta\",\n",
    "    \"Developer Reply\": \"developer_reply_text\",\n",
    "    \"Translated title\": \"translated_title\",\n",
    "    \"Translated review\": \"translated_review\",\n",
    "    \"Link\": \"review_link\",\n",
    "    \"Permalink\": \"review_permalink\",\n",
    "    \"Updated\": \"updated_at\",\n",
    "    # Metadata or optional context\n",
    "    \"Device Name\": \"device_name\",\n",
    "    \"VersionCode\": \"version_code\",\n",
    "    \"OS\": \"os_version\"\n",
    "}\n",
    "\n",
    "\n",
    "# Columns to drop entirely (empty or redundant in all datasets)\n",
    "drop_columns = [\n",
    "    \"Tags\", \"User\", \"Notes\", \"Semantic Tags\",\n",
    "    \"Semantic Categories\", \"Semantic Sentiment\",\n",
    "    \"Categories\", \"Likes\", \"Dislikes\", \"AF Link\"\n",
    "]\n"
   ],
   "id": "6d6e08e7bbdaabaf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5.2 Harmonisation Function\n",
    "# ------------------------------------------------------------\n",
    "def harmonise_dataset(df, platform_name):\n",
    "    \"\"\"\n",
    "    Standardise schema for App Store / Google Play datasets.\n",
    "\n",
    "    Steps:\n",
    "    - Rename columns using mapping dictionary.\n",
    "    - Drop redundant / empty columns.\n",
    "    - Add 'platform' column (iOS / Android).\n",
    "    - Convert 'review_date' to datetime and 'rating' to numeric.\n",
    "    \"\"\"\n",
    "    df = df.rename(columns=column_mapping)\n",
    "    df = df.drop(columns=[col for col in drop_columns if col in df.columns], errors=\"ignore\")\n",
    "    df[\"platform\"] = platform_name\n",
    "\n",
    "    # Clean data types\n",
    "    if \"review_date\" in df.columns:\n",
    "        df[\"review_date\"] = pd.to_datetime(df[\"review_date\"], errors=\"coerce\")\n",
    "    if \"rating\" in df.columns:\n",
    "        df[\"rating\"] = pd.to_numeric(df[\"rating\"], errors=\"coerce\")\n",
    "\n",
    "    # Optional: Keep only core columns\n",
    "    core_cols = [\n",
    "        \"review_date\", \"rating\", \"review_title\", \"review_text\", \"author_name\",\n",
    "        \"app_version\", \"country\", \"review_language\", \"developer_reply_text\",\n",
    "        \"developer_reply_date\", \"platform\"\n",
    "    ]\n",
    "    return df[[col for col in core_cols if col in df.columns]]\n"
   ],
   "id": "c5e8080a314508dc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ------------------------------------------------------------\n",
    "# 5.3 Apply Harmonisation to Each Dataset\n",
    "# ------------------------------------------------------------\n",
    "harmonised = []\n",
    "for name, df in datasets.items():\n",
    "    platform = \"iOS\" if \"appstore\" in name.lower() else \"Android\"\n",
    "    cleaned_df = harmonise_dataset(df.copy(), platform)\n",
    "    harmonised.append(cleaned_df)\n",
    "    print(f\"âœ… Harmonised {name} ({platform}) â†’ {cleaned_df.shape[0]:,} rows, {cleaned_df.shape[1]} cols\")\n"
   ],
   "id": "25aa9da86155e7ed"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5.4 Merge All Reviews into One Master Dataset\n",
    "# ------------------------------------------------------------\n",
    "monzo_reviews_master = pd.concat(harmonised, ignore_index=True)\n",
    "print(f\"\\nðŸ”— Combined dataset shape: {monzo_reviews_master.shape}\")\n",
    "print(f\"   Unique platforms: {monzo_reviews_master['platform'].unique().tolist()}\")\n"
   ],
   "id": "1252087e7838f17a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ------------------------------------------------------------\n",
    "# 5.5 Export Cleaned & Harmonised Dataset\n",
    "# ------------------------------------------------------------\n",
    "output_dir = \"../data/processed\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_path = os.path.join(output_dir, \"Monzo_Reviews_Master.csv\")\n",
    "\n",
    "monzo_reviews_master.to_csv(output_path, index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"\\nðŸ’¾ Exported unified dataset to: {output_path}\")"
   ],
   "id": "737ac6ab5d8cdff6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ------------------------------------------------------------\n",
    "# 5.6 Quick Sanity Checks\n",
    "# ------------------------------------------------------------\n",
    "print(\"\\nðŸ“Š Sanity Checks:\")\n",
    "print(\"Date Range:\", monzo_reviews_master[\"review_date\"].min(), \"â†’\", monzo_reviews_master[\"review_date\"].max())\n",
    "print(\"Average Rating:\", round(monzo_reviews_master[\"rating\"].mean(), 2))\n",
    "print(\"Sample rows:\")\n",
    "display(monzo_reviews_master.sample(5, random_state=42))\n"
   ],
   "id": "b5a3eb4dd189279a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\"\"\"\n",
    "Outcome:\n",
    "---------\n",
    "âœ… All Monzo App Store and Google Play datasets successfully harmonised.\n",
    "âœ… Final dataset ready for exploratory analysis and sentiment modelling.\n",
    "âœ… Exported to '../data/processed/Monzo_Reviews_Master.csv'.\n",
    "\"\"\""
   ],
   "id": "8f8e3049024f312a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\"\"\"\n",
    "Before Jumping to Section 6 (Sentiment)\n",
    "\n",
    "The next smart step is data readiness validation, Handle Missing Values and we'll focus on these review_text, rating, review_date, optionally (review_language and platform)\n",
    "\"\"\""
   ],
   "id": "f412d05f4d4b8e15"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#Checking for missing values (NaNs)\n",
    "print(\"Checking for missing values (NaNs)\")\n",
    "monzo_reviews_master[['review_text','rating','review_date','review_language']].isna().sum()\n"
   ],
   "id": "cab04441f9bc2f82"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#Apply light cleaning\n",
    "# Drop empty or invalid reviews\n",
    "monzo_reviews_master = monzo_reviews_master.dropna(subset=['review_text'])\n",
    "\n",
    "# Replace missing ratings with 0 or drop them\n",
    "monzo_reviews_master = monzo_reviews_master.dropna(subset=['rating'])\n",
    "\n",
    "# Normalise language codes (fallback to 'en')\n",
    "monzo_reviews_master['review_language'] = (\n",
    "    monzo_reviews_master['review_language']\n",
    "    .fillna('en')\n",
    "    .str.lower()\n",
    ")\n"
   ],
   "id": "8de115571f436185"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Identify all non-English reviews\n",
    "non_english_reviews = monzo_reviews_master[monzo_reviews_master['review_language'] != 'en']\n",
    "\n",
    "# Basic info\n",
    "print(f\"ðŸŒ Non-English reviews: {len(non_english_reviews):,}\")\n",
    "print(f\"Languages present: {non_english_reviews['review_language'].unique()}\")\n",
    "\n",
    "# View a few examples\n",
    "display(non_english_reviews[['review_language', 'review_text']].sample(15, random_state=42))\n"
   ],
   "id": "cbe84e4d1831b009"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(\"Remaining rows:\", len(monzo_reviews_master))\n",
    "print(\"Unique languages:\", monzo_reviews_master['review_language'].unique())\n",
    "print(\"Nulls per column:\\n\", monzo_reviews_master.isna().sum())\n"
   ],
   "id": "45fe1e08c62f61d4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Reclassify & Annotate NaN or Misdetected Languages",
   "id": "4ca503fdb0f6b79"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import langdetect\n",
    "from langdetect import DetectorFactory\n",
    "DetectorFactory.seed = 42  # ensures reproducibility\n",
    "\n",
    "def detect_language_safe(text):\n",
    "    \"\"\"Safely detect language using langdetect with fallback.\"\"\"\n",
    "    try:\n",
    "        if isinstance(text, str) and len(text.strip()) > 5:\n",
    "            lang = langdetect.detect(text)\n",
    "            return lang\n",
    "        else:\n",
    "            return None\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "# 1ï¸âƒ£ Extract the 366 non-English or NaN-labelled reviews\n",
    "suspect_reviews = monzo_reviews_master[\n",
    "    (monzo_reviews_master['review_language'].isna()) |\n",
    "    (monzo_reviews_master['review_language'] != 'en')\n",
    "].copy()\n",
    "\n",
    "print(f\"ðŸ” Reviewing {len(suspect_reviews):,} suspect language rows...\")\n",
    "\n",
    "# 2ï¸âƒ£ Detect language again for these reviews\n",
    "suspect_reviews['detected_lang'] = suspect_reviews['review_text'].apply(detect_language_safe)\n",
    "\n",
    "# 3ï¸âƒ£ Check where the new detection finds English content\n",
    "english_like = suspect_reviews[suspect_reviews['detected_lang'] == 'en']\n",
    "\n",
    "print(f\"âœ… Reclassified {len(english_like):,} as English from the suspect set.\")\n",
    "\n",
    "# 4ï¸âƒ£ Update main dataset\n",
    "monzo_reviews_master.loc[english_like.index, 'review_language'] = 'en'\n",
    "\n",
    "# 5ï¸âƒ£ Optional sanity check\n",
    "print(\"ðŸ”  Updated language distribution:\\n\", monzo_reviews_master['review_language'].value_counts().head(10))\n",
    "\n",
    "# 6ï¸âƒ£ Save reclassified subset for audit\n",
    "english_like[['review_text', 'review_language', 'detected_lang']].to_csv(\n",
    "    \"../data/processed/Monzo_Reclassified_English.csv\",\n",
    "    index=False, encoding=\"utf-8-sig\"\n",
    ")\n",
    "print(\"ðŸ’¾ Saved reclassified English reviews for audit.\")\n"
   ],
   "id": "4d251c82bdf6a4c9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# suspect_reviews = monzo_reviews_master[monzo_reviews_master['review_language'].isna()].copy()\n",
   "id": "4a5937eccd13519e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Filter remaining non-English reviews\n",
    "non_en_remaining = monzo_reviews_master[monzo_reviews_master[\"review_language\"] != \"en\"]\n",
    "\n",
    "print(f\"ðŸŒ Remaining non-English reviews: {len(non_en_remaining):,}\")\n",
    "print(f\"Languages still present: {sorted(non_en_remaining['review_language'].dropna().unique().tolist())}\")\n",
    "\n",
    "# Show random samples per language\n",
    "for lang in non_en_remaining[\"review_language\"].dropna().unique():\n",
    "    print(f\"\\nðŸ—£ï¸ Language: {lang}\")\n",
    "\n",
    "    lang_reviews = non_en_remaining[non_en_remaining[\"review_language\"] == lang][\"review_text\"]\n",
    "    sample_size = min(3, len(lang_reviews))\n",
    "\n",
    "    sample = lang_reviews.sample(sample_size, random_state=42)\n",
    "\n",
    "    for text in sample:\n",
    "        print(f\"  - {text[:200]}\")\n",
    "\n"
   ],
   "id": "631bdd7d8fa6527e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import re\n",
    "from langdetect import detect\n",
    "from langdetect.lang_detect_exception import LangDetectException\n",
    "\n",
    "def is_mostly_english(text):\n",
    "    \"\"\"\n",
    "    Checks if >60% of words are likely English using dictionary and langdetect.\n",
    "    Returns True if confidently English.\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str) or len(text) < 3:\n",
    "        return False\n",
    "\n",
    "    # Tokenise text and count English-like words\n",
    "    english_words = re.findall(r\"\\b(?:bank|money|monzo|love|good|great|best|app|amazing|easy|help|support|thank|brilliant|nice|card|account|customer|issue|login|transfer|recommend)\\b\", text.lower())\n",
    "    total_words = len(re.findall(r\"[a-zA-Z]+\", text))\n",
    "\n",
    "    ratio = len(english_words) / total_words if total_words else 0\n",
    "\n",
    "    # Confirm with langdetect if uncertain\n",
    "    try:\n",
    "        lang = detect(text)\n",
    "    except LangDetectException:\n",
    "        lang = None\n",
    "\n",
    "    return (ratio > 0.5) or (lang == \"en\")\n",
    "\n",
    "# Apply the refined filter only on non-English labels\n",
    "suspect_idx = monzo_reviews_master[\n",
    "    (monzo_reviews_master[\"review_language\"] != \"en\") &\n",
    "    (monzo_reviews_master[\"review_text\"].apply(is_mostly_english))\n",
    "].index\n",
    "\n",
    "# Update the language tag\n",
    "monzo_reviews_master.loc[suspect_idx, \"review_language\"] = \"en\"\n",
    "\n",
    "print(f\"âœ… Reclassified {len(suspect_idx)} reviews as English (validated by ratio & langdetect).\")\n",
    "\n",
    "# Optional: audit export\n",
    "monzo_reviews_master.loc[suspect_idx].to_csv(\n",
    "    \"../data/processed/Monzo_Reclassified_English_Validated.csv\",\n",
    "    index=False,\n",
    "    encoding=\"utf-8\"\n",
    ")\n"
   ],
   "id": "22a451b74fff0033"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Show 10 rows of the reclassified data\n",
    "print(\"\")\n",
    "monzo_reviews_master.loc[suspect_idx].head(10)\n",
    "\n"
   ],
   "id": "4dfa357ba3f3d24b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Light Pre-Sentiment Cleaning",
   "id": "8ad45fb47115c988"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# # ------------------------------------------------------------\n",
    "# # 5.X Pre-Sentiment Data Preparation\n",
    "# # ------------------------------------------------------------\n",
    "#\n",
    "# # Drop rows with missing review text\n",
    "# monzo_reviews_master = monzo_reviews_master.dropna(subset=['review_text'])\n",
    "#\n",
    "# # Fill missing author and language\n",
    "# monzo_reviews_master['author_name'] = monzo_reviews_master['author_name'].fillna('Unknown')\n",
    "# monzo_reviews_master['review_language'] = monzo_reviews_master['review_language'].fillna('en').str.lower()\n",
    "#\n",
    "# # Keep only English reviews for sentiment analysis\n",
    "# monzo_reviews_master = monzo_reviews_master[monzo_reviews_master['review_language'] == 'en']\n",
    "#\n",
    "# # Strip whitespace and remove duplicates\n",
    "# monzo_reviews_master['review_text'] = monzo_reviews_master['review_text'].astype(str).str.strip()\n",
    "# monzo_reviews_master = monzo_reviews_master.drop_duplicates(subset=['review_text'])\n",
    "#\n",
    "# # Sanity check after cleaning\n",
    "# print(\"âœ… Cleaned dataset ready for sentiment analysis\")\n",
    "# print(f\"Remaining rows: {len(monzo_reviews_master):,}\")\n",
    "# print(\"Unique languages:\", monzo_reviews_master['review_language'].unique())\n"
   ],
   "id": "b1792dfc6c5bc042"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
